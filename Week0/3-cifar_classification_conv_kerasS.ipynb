{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 0: Introduction to Deep Learning Frameworks\n",
    "\n",
    "## Notebook 3: CIFAR Classification with a Convolutional Neural Network on Keras\n",
    "\n",
    "Welcome to the last notebook of the deep learning frameworks week. In this notebook we will train a convolutional neural network on Keras. We are changing our dataset to CIFAR-10 this time. This dataset contains RGB images belonging to 10 classes such as airplane, car, and, bird.\n",
    "\n",
    "## 0. Problem Definition\n",
    "\n",
    "In this notebook, our problem is once more... (you guessed it!) **classification**. However, this time we are using the [Cifar10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset. This is another widely used classification dataset but the images are colored and the categories are different than MNIST.\n",
    "\n",
    "## 1. Install Keras\n",
    "\n",
    "If you already installed TensorFlow, you also have Keras installed! Keras completely works with TensorFlow as its backend and provides a high-level API to build and train neural networks.\n",
    "\n",
    "If you did not install TensorFlow, simply run the command:\n",
    "\n",
    "    pip install tensorflow\n",
    "    \n",
    "Now let's move on to our imports:\n",
    "\n",
    "## 2. Imports\n",
    "\n",
    "As always, we start with our necessary imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation\n",
    "\n",
    "Keras also has a dataset API that lets you download and directly use some famous datasets. Luckily, Cifar10 is one of them. We load the dataset by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check the shapes of the dataset below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We move on to visualize the first training image using `matplotlib` and also print its label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_train[0])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check and see that the maximum and minimum pixel values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.amax(x_train[0]),np.amin(x_train[0]))\n",
    "print(np.amax(y_train),np.amin(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we normalize the data and cast the pixel values to `float32`. We use the `to_categorical` function of Keras to obtain one-hot vectors of the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data is ready, let's move on to building the model.\n",
    "\n",
    "## 4. Model Creation\n",
    "\n",
    "We use Keras Sequential API to build our model. We have three convolutional layers along with max pooling, dropout, and batch normalization operations. At the end, we have a flatten layer and a final dense layer with a `softmax` activation to get the probabilities for each class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, BatchNormalization, Dropout, Dense, Flatten, MaxPool2D\n",
    "from keras.models import Sequential\n",
    "\n",
    "inzvaNet = Sequential()\n",
    "\n",
    "inzvaNet.add(BatchNormalization())\n",
    "inzvaNet.add(Conv2D(64,(5,5),activation = 'tanh', padding = 'same'))\n",
    "inzvaNet.add(MaxPool2D())\n",
    "inzvaNet.add(Dropout(0.2))\n",
    "\n",
    "inzvaNet.add(BatchNormalization())\n",
    "inzvaNet.add(Conv2D(128,(5,5),activation = 'tanh', padding = 'same'))\n",
    "inzvaNet.add(MaxPool2D())\n",
    "inzvaNet.add(Dropout(0.2))\n",
    "\n",
    "inzvaNet.add(BatchNormalization())\n",
    "inzvaNet.add(Conv2D(256,(5,5),activation = 'tanh', padding = 'same'))\n",
    "inzvaNet.add(MaxPool2D())\n",
    "inzvaNet.add(Dropout(0.2))\n",
    "\n",
    "inzvaNet.add(Flatten())\n",
    "inzvaNet.add(Dense(10,activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the optimizer and compile our network to make it ready for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "opt = Adam(learning_rate = 0.001)\n",
    "\n",
    "inzvaNet.compile(optimizer = opt,\n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training\n",
    "\n",
    "Training is only one line with Keras! We run the `fit` function with the necessary arguments and Keras starts the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inzvaNet.fit(x_train, y_train, batch_size=100, epochs=4, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation\n",
    "\n",
    "Let's run the evaluation and see the accuracy of our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inzvaNet.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's see some of the predictions of the model along with their ground truth values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randind = int(random.random() * 1000)\n",
    "plt.imshow(x_test[randind])\n",
    "print(np.argmax(inzvaNet.predict(x_test[[randind]])))\n",
    "print(np.argmax(y_test[randind]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You made it through the framework notebooks ðŸŽ‰ ðŸŽŠ.\n",
    "\n",
    "We strongly encourage you to to through the documentation of each framework and go through some other examples, as well.\n",
    "\n",
    "See you at the first week of the program!\n",
    "\n",
    "**Bonus - Try to:**\n",
    "\n",
    "- Get a test image\n",
    "- Plot the image\n",
    "- Make a model prediction on the image\n",
    "- Print the predicted label and the actual label!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
