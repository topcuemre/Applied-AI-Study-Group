{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1- NLP Tasks.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"cells":[{"cell_type":"markdown","metadata":{"id":"RfrF_eQ9zaUa"},"source":["\"Coursera DeepLearning AI Deep Learning Specialization Sequence Models\"\n","\n","\"Coursera DeepLearning AI NLP Specialization\"\n","\n","- Tensorflow NLP Tutorial, Tensorflow Hub NLP Models\n","- Huggingface\n","- AllenNLP\n","- Pytorch"]},{"cell_type":"markdown","metadata":{"tags":[],"id":"l3FdKky-nsgM"},"source":["# NLP Tasks\n","\n","In this notebook, we will examine some of the currently popular NLP tasks. We use some of the popular open-sourced NLP frameworks/libraries to do that.\n","\n","There will be no training (backpropagation) in this notebook. We are only interested in making predictions with models, to understand the nature of the tasks.\n","\n","**Tasks to cover in this notebook:**\n","\n","1. (extractive) Question Answering\n","2. Named Entity Recognition (also called token tagging, or, entity extraction)\n","3. Sentiment Analysis (a specific case of text classification)\n","4. Text Generation\n","5. Conversetional Agents\n","\n","**Important eye-opener:** All of the tasks in this notebook could be modelled in another way than we do here. However, we tried to show you the most popular ways as of 2021 to perform these tasks. For example, sentiment analysis task could be modelled as a regression problem, rather than a multi-class classification problem."]},{"cell_type":"markdown","metadata":{"id":"RE5Da5H8qgtb","tags":[]},"source":["## 1- Using AllenNLP\n","\n","AllenNLP is an open source NLP framework formed by Allen Institute for AI, a private company & research institute. AI2 is founded by Paul Allen, one of the co-founders of Microsoft.\n","\n","![image.png](attachment:84ffb7d1-ee1a-4ed7-b31f-0242d978f0df.png)"]},{"cell_type":"markdown","metadata":{"id":"jgnqHGVwnsgU"},"source":["____"]},{"cell_type":"markdown","metadata":{"id":"6uuu1giIqgtg"},"source":["Codes below are obtained from AllenNLP demo site. There are more tasks there. We will examine only three of them.\n","\n","- https://demo.allennlp.org"]},{"cell_type":"markdown","metadata":{"id":"-UTjwdMfqgtg","tags":[]},"source":["### a- Reading Comprehension (Question Answering)"]},{"cell_type":"markdown","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[],"id":"V1AAMtdUnsgW"},"source":["Question answering is the task of extracting text spans from context paragraphs. While doing the extraction model also takes a question into account.\n","\n","- Inputs: Context Paragraph (tokenized string), Question (tokenized string)\n","- Outputs: A text span (de-tokenized list of tokens), named as the \"Answer\"\n","- Popular Methods: BERT based QA models\n","\n","![QA.jpg](attachment:e040814c-2db4-4b88-9a40-2370a67eaead.jpg)\n","\n","In the example, we see a context paragraph, giving information on inzva. Then, we have a question, asking inzva's foundation date.\n","\n","We basically ask the model this question: \n","\n","- **If we have N tokens in the context, what is the likelihood of $n^{\\text{th}}$ token to be the start token of the answer. Likewise, what is the likelihood for each token to be the ending token of the answer?**\n","- By asking that, we find the most likely start and end positions for the answer span.\n","- Then we can get the answer span between the most likely start token and the most likely end token. \n","- In the example, token \"2017\" is the most likely token to be the start token. It is also most likely to be the end token. Between the most likely start token and the most likely end token, the only word is \"2017\" so we take that as the answer.\n","\n","___"]},{"cell_type":"markdown","metadata":{"id":"kUIQ9rNjnsgX"},"source":["We install allennlp_models to use the pretrained models in AllenNLP"]},{"cell_type":"code","metadata":{"id":"_cB1bPkVqmMn"},"source":["!pip install allennlp allennlp_models\n","!pip install --upgrade google-cloud-storage"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FOR8FCsonsga"},"source":["Then we import the Predictor class, which is a wrapper for ML Model classes."]},{"cell_type":"code","metadata":{"id":"WdhPOs9mqgth"},"source":["from allennlp.predictors.predictor import Predictor\n","import allennlp_models.rc"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B3m6fvtXnsgb"},"source":["We instantiate a Predictor instance which is a QA Model in our case."]},{"cell_type":"code","metadata":{"id":"plaF4cZeqgth"},"source":["qa_model = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/bidaf-elmo-model-2020.03.19.tar.gz\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6hhJpGa7nsgc"},"source":["We make the predictions with the two necessary parameters. Question and the context passage. The answer will be selected from inside the context passage."]},{"cell_type":"code","metadata":{"id":"l_hWMAllqgti","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638023637406,"user_tz":-180,"elapsed":2074,"user":{"displayName":"Ahmet Melek","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWk81Nf32Tf0d0Jd6FX00TlioZ89O4UvaQrXdDOF6rUjBLzllwxAMrqh7j_piGK3NZPNt8c943aizmixPIoJNMqmMXgONFthAtwewKLJkeB6TozbkGlSGdH-1yU4E5VnpIA_-S5-N8eF2kk60G8SbMfmKTy0N1dZU6_1-j82cbTVyeiFgaGYukRi-Ul8Ve-TDOYROSzLMODA5YBkToostv-ChNd2IxX_faPKi4Rbk_FEaltxOILTkejo_6jd5y6uHC9LbIdpHKyILCt6fSJVSdiPOlEsHuFn-gv_2cF18K6zcjZrmv-GHM1GpaACBRr_-rBTRa-SZzrfflh24eI1f_DFT8G04K_dcqBE1nQIBgROvfGHaXSqhRXf3TFCTtB2RNnnNyNxADSuv5VnK51HAebBT8WZ4d_YZOgnQorLQEjEuCEBZgRZIn22AyaTNNEgrVvpKjEhiz6aAwCQ0xCQBDiHCVaNR6Q-X2yC2Q7WMTvppUp1Ik0sR8eC1mJBb94LObDGwZoaSMkuxm08Gsu6w_Wseg4gHgcH0jkWmNq0sEYGDea6SoY5vVCy9h_fVnWJOr-C_Il53t9qcsf0Hoq5tTpWGdryp4mB2vbGGb27ju3Tug8U64cLbEzAlOJfaSsaQQx-UR1mWde_tuwTrOZgKVhJ2yNgZ10vpz0UIIN028VFM6vUBysE_Ufio6A7nGB89r7xu8SiVNll_JG5ejRejc7_uniW_K4DoJmW853OyVPEa8sZFZEjl_kjeQFL_j9DmeaA=s64","userId":"17547825594365273093"}},"outputId":"77020979-51cc-47ad-9dee-372c28c1cc0c"},"source":["results = qa_model.predict(\n","  passage=\"The Matrix is a 1999 science fiction action film written and directed by The Wachowskis, starring Keanu Reeves, Laurence Fishburne, Carrie-Anne Moss, Hugo Weaving, and Joe Pantoliano.\",\n","  question=\"What was the budget of The Matrix?\")"],"execution_count":38,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/allennlp_models/rc/models/utils.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  span_start_indices = best_spans // passage_length\n"]}]},{"cell_type":"markdown","metadata":{"id":"-1j57iwlnsgd"},"source":["We print three things:\n","- Our context (just to see it)\n","- The question (just to see it)\n","- The answer, which is in the key *best_span_str* ."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oJUVWjMk1BIS","executionInfo":{"status":"ok","timestamp":1638023844951,"user_tz":-180,"elapsed":1746,"user":{"displayName":"Ahmet Melek","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWk81Nf32Tf0d0Jd6FX00TlioZ89O4UvaQrXdDOF6rUjBLzllwxAMrqh7j_piGK3NZPNt8c943aizmixPIoJNMqmMXgONFthAtwewKLJkeB6TozbkGlSGdH-1yU4E5VnpIA_-S5-N8eF2kk60G8SbMfmKTy0N1dZU6_1-j82cbTVyeiFgaGYukRi-Ul8Ve-TDOYROSzLMODA5YBkToostv-ChNd2IxX_faPKi4Rbk_FEaltxOILTkejo_6jd5y6uHC9LbIdpHKyILCt6fSJVSdiPOlEsHuFn-gv_2cF18K6zcjZrmv-GHM1GpaACBRr_-rBTRa-SZzrfflh24eI1f_DFT8G04K_dcqBE1nQIBgROvfGHaXSqhRXf3TFCTtB2RNnnNyNxADSuv5VnK51HAebBT8WZ4d_YZOgnQorLQEjEuCEBZgRZIn22AyaTNNEgrVvpKjEhiz6aAwCQ0xCQBDiHCVaNR6Q-X2yC2Q7WMTvppUp1Ik0sR8eC1mJBb94LObDGwZoaSMkuxm08Gsu6w_Wseg4gHgcH0jkWmNq0sEYGDea6SoY5vVCy9h_fVnWJOr-C_Il53t9qcsf0Hoq5tTpWGdryp4mB2vbGGb27ju3Tug8U64cLbEzAlOJfaSsaQQx-UR1mWde_tuwTrOZgKVhJ2yNgZ10vpz0UIIN028VFM6vUBysE_Ufio6A7nGB89r7xu8SiVNll_JG5ejRejc7_uniW_K4DoJmW853OyVPEa8sZFZEjl_kjeQFL_j9DmeaA=s64","userId":"17547825594365273093"}},"outputId":"a044fb8f-0f8d-44ef-f3ec-173788d95436"},"source":["results = qa_model.predict(\n","  passage=\"The Matrix is a 1999 science fiction action film written and directed by The Wachowskis, starring Keanu Reeves, Laurence Fishburne, Carrie-Anne Moss, Hugo Weaving, and Joe Pantoliano.\",\n","  question=\"When was the Matrix produced?\")"],"execution_count":46,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/allennlp_models/rc/models/utils.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  span_start_indices = best_spans // passage_length\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5dE08BSp1Flk","executionInfo":{"status":"ok","timestamp":1638023849393,"user_tz":-180,"elapsed":323,"user":{"displayName":"Ahmet Melek","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWk81Nf32Tf0d0Jd6FX00TlioZ89O4UvaQrXdDOF6rUjBLzllwxAMrqh7j_piGK3NZPNt8c943aizmixPIoJNMqmMXgONFthAtwewKLJkeB6TozbkGlSGdH-1yU4E5VnpIA_-S5-N8eF2kk60G8SbMfmKTy0N1dZU6_1-j82cbTVyeiFgaGYukRi-Ul8Ve-TDOYROSzLMODA5YBkToostv-ChNd2IxX_faPKi4Rbk_FEaltxOILTkejo_6jd5y6uHC9LbIdpHKyILCt6fSJVSdiPOlEsHuFn-gv_2cF18K6zcjZrmv-GHM1GpaACBRr_-rBTRa-SZzrfflh24eI1f_DFT8G04K_dcqBE1nQIBgROvfGHaXSqhRXf3TFCTtB2RNnnNyNxADSuv5VnK51HAebBT8WZ4d_YZOgnQorLQEjEuCEBZgRZIn22AyaTNNEgrVvpKjEhiz6aAwCQ0xCQBDiHCVaNR6Q-X2yC2Q7WMTvppUp1Ik0sR8eC1mJBb94LObDGwZoaSMkuxm08Gsu6w_Wseg4gHgcH0jkWmNq0sEYGDea6SoY5vVCy9h_fVnWJOr-C_Il53t9qcsf0Hoq5tTpWGdryp4mB2vbGGb27ju3Tug8U64cLbEzAlOJfaSsaQQx-UR1mWde_tuwTrOZgKVhJ2yNgZ10vpz0UIIN028VFM6vUBysE_Ufio6A7nGB89r7xu8SiVNll_JG5ejRejc7_uniW_K4DoJmW853OyVPEa8sZFZEjl_kjeQFL_j9DmeaA=s64","userId":"17547825594365273093"}},"outputId":"f0b785f4-1237-4b1e-def4-ac2b1ce4fe8e"},"source":["for i,item in enumerate(zip(results[\"span_start_probs\"],results[\"span_end_probs\"])):\n","  print(item,results[\"passage_tokens\"][i])"],"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["(0.0059886048547923565, 2.97971346299164e-05) The\n","(0.0001135591883212328, 0.0006942124455235898) Matrix\n","(5.7538458349881694e-05, 6.995798685238697e-06) is\n","(0.010700530372560024, 3.842319074465195e-06) a\n","(0.9811098575592041, 0.926461935043335) 1999\n","(0.0010354286059737206, 0.001707791117951274) science\n","(9.498111467109993e-05, 0.06849149614572525) fiction\n","(0.0007048737606965005, 0.0002805436379276216) action\n","(6.459171345341019e-06, 0.0015518845757469535) film\n","(3.282208854216151e-05, 3.1104493245948106e-05) written\n","(7.363278655247996e-06, 5.626451638818253e-06) and\n","(4.694305062002968e-06, 1.7014330296660773e-05) directed\n","(3.94298604078358e-06, 3.605018264352111e-06) by\n","(3.9204904169309884e-05, 1.9755302673729602e-06) The\n","(3.605255187721923e-05, 0.00020484124252106994) Wachowskis\n","(2.881515115404909e-07, 2.4242624931503087e-05) ,\n","(7.164513249335869e-07, 2.4717949145269813e-06) starring\n","(1.8673377780942246e-05, 2.75472120847553e-06) Keanu\n","(2.4421214561698434e-07, 6.814272637711838e-05) Reeves\n","(2.581923119748808e-08, 8.347038829015219e-07) ,\n","(3.487326921458589e-06, 2.6728614557214314e-06) Laurence\n","(1.2923781866902573e-07, 1.0524204299144913e-05) Fishburne\n","(2.2809174993199122e-08, 8.699369118403411e-07) ,\n","(3.1897488952381536e-06, 2.863697773136664e-06) Carrie\n","(3.818659877197206e-08, 1.2511682712101901e-07) -\n","(1.0187371799474931e-06, 1.5632201666448964e-06) Anne\n","(1.1041147729429213e-07, 2.7450299967313185e-05) Moss\n","(3.739047826911701e-08, 1.0982757885358296e-06) ,\n","(4.5918632167740725e-06, 1.6353778846678324e-06) Hugo\n","(4.810136147170851e-07, 5.949145634076558e-05) Weaving\n","(6.706637378783853e-08, 1.864983119048702e-06) ,\n","(6.20772624415622e-08, 4.0249784660773e-07) and\n","(8.00055840954883e-06, 1.1100864867330529e-06) Joe\n","(5.511073482011852e-07, 8.708790846867487e-05) Pantoliano\n","(2.23429269681219e-05, 0.00021020388521719724) .\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PE9gJri20baC","executionInfo":{"status":"ok","timestamp":1638023815363,"user_tz":-180,"elapsed":319,"user":{"displayName":"Ahmet Melek","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWk81Nf32Tf0d0Jd6FX00TlioZ89O4UvaQrXdDOF6rUjBLzllwxAMrqh7j_piGK3NZPNt8c943aizmixPIoJNMqmMXgONFthAtwewKLJkeB6TozbkGlSGdH-1yU4E5VnpIA_-S5-N8eF2kk60G8SbMfmKTy0N1dZU6_1-j82cbTVyeiFgaGYukRi-Ul8Ve-TDOYROSzLMODA5YBkToostv-ChNd2IxX_faPKi4Rbk_FEaltxOILTkejo_6jd5y6uHC9LbIdpHKyILCt6fSJVSdiPOlEsHuFn-gv_2cF18K6zcjZrmv-GHM1GpaACBRr_-rBTRa-SZzrfflh24eI1f_DFT8G04K_dcqBE1nQIBgROvfGHaXSqhRXf3TFCTtB2RNnnNyNxADSuv5VnK51HAebBT8WZ4d_YZOgnQorLQEjEuCEBZgRZIn22AyaTNNEgrVvpKjEhiz6aAwCQ0xCQBDiHCVaNR6Q-X2yC2Q7WMTvppUp1Ik0sR8eC1mJBb94LObDGwZoaSMkuxm08Gsu6w_Wseg4gHgcH0jkWmNq0sEYGDea6SoY5vVCy9h_fVnWJOr-C_Il53t9qcsf0Hoq5tTpWGdryp4mB2vbGGb27ju3Tug8U64cLbEzAlOJfaSsaQQx-UR1mWde_tuwTrOZgKVhJ2yNgZ10vpz0UIIN028VFM6vUBysE_Ufio6A7nGB89r7xu8SiVNll_JG5ejRejc7_uniW_K4DoJmW853OyVPEa8sZFZEjl_kjeQFL_j9DmeaA=s64","userId":"17547825594365273093"}},"outputId":"20e80c99-700b-49f9-9e42-e8b937107ca3"},"source":["for i,item in enumerate(zip(results[\"span_start_probs\"],results[\"span_end_probs\"])):\n","  print(item,results[\"passage_tokens\"][i])"],"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["(0.3534693419933319, 0.012056135572493076) The\n","(0.0026501340325921774, 0.07330133765935898) Matrix\n","(0.0023868922144174576, 0.0028157872147858143) is\n","(0.05499861389398575, 0.0011885670246556401) a\n","(0.4507535994052887, 0.3042233884334564) 1999\n","(0.04138783738017082, 0.009345144033432007) science\n","(0.0032744486816227436, 0.25432443618774414) fiction\n","(0.02548595890402794, 0.003398345550522208) action\n","(0.0006183712393976748, 0.0387117974460125) film\n","(0.0015431317733600736, 0.0017001550877466798) written\n","(0.000730712607037276, 0.0003484560002107173) and\n","(0.00040637326310388744, 0.0013140913797542453) directed\n","(8.344931848114356e-05, 0.00019434303976595402) by\n","(0.007540808524936438, 8.336621976923198e-05) The\n","(0.007430798374116421, 0.026591921225190163) Wachowskis\n","(5.0442733481759205e-05, 0.002453346736729145) ,\n","(6.61697777104564e-05, 0.00025419832672923803) starring\n","(0.002071676542982459, 0.0003216151671949774) Keanu\n","(6.931848474778235e-05, 0.007053593639284372) Reeves\n","(9.893746209854726e-06, 0.0001815897412598133) ,\n","(0.0017128087347373366, 0.0005813709576614201) Laurence\n","(0.00016384333139285445, 0.004078513011336327) Fishburne\n","(1.7635289623285644e-05, 0.0002566380426287651) ,\n","(0.0027637674938887358, 0.0009700985974632204) Carrie\n","(1.83763841050677e-05, 3.813981675193645e-05) -\n","(0.00044343803892843425, 0.0004696363175753504) Anne\n","(0.00010135573393199593, 0.00700752530246973) Moss\n","(1.8523480321164243e-05, 0.000327923393342644) ,\n","(0.002572115743532777, 0.0006198454648256302) Hugo\n","(0.00020105043950024992, 0.007558299228549004) Weaving\n","(3.436773840803653e-05, 0.0004507386183831841) ,\n","(4.071263174409978e-05, 0.00011316529707983136) and\n","(0.005390940699726343, 0.00034857168793678284) Joe\n","(0.0005835123010911047, 0.058195870369672775) Pantoliano\n","(0.030909620225429535, 0.17912210524082184) .\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J1gj-Q6q0zEQ","executionInfo":{"status":"ok","timestamp":1638023782641,"user_tz":-180,"elapsed":407,"user":{"displayName":"Ahmet Melek","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWk81Nf32Tf0d0Jd6FX00TlioZ89O4UvaQrXdDOF6rUjBLzllwxAMrqh7j_piGK3NZPNt8c943aizmixPIoJNMqmMXgONFthAtwewKLJkeB6TozbkGlSGdH-1yU4E5VnpIA_-S5-N8eF2kk60G8SbMfmKTy0N1dZU6_1-j82cbTVyeiFgaGYukRi-Ul8Ve-TDOYROSzLMODA5YBkToostv-ChNd2IxX_faPKi4Rbk_FEaltxOILTkejo_6jd5y6uHC9LbIdpHKyILCt6fSJVSdiPOlEsHuFn-gv_2cF18K6zcjZrmv-GHM1GpaACBRr_-rBTRa-SZzrfflh24eI1f_DFT8G04K_dcqBE1nQIBgROvfGHaXSqhRXf3TFCTtB2RNnnNyNxADSuv5VnK51HAebBT8WZ4d_YZOgnQorLQEjEuCEBZgRZIn22AyaTNNEgrVvpKjEhiz6aAwCQ0xCQBDiHCVaNR6Q-X2yC2Q7WMTvppUp1Ik0sR8eC1mJBb94LObDGwZoaSMkuxm08Gsu6w_Wseg4gHgcH0jkWmNq0sEYGDea6SoY5vVCy9h_fVnWJOr-C_Il53t9qcsf0Hoq5tTpWGdryp4mB2vbGGb27ju3Tug8U64cLbEzAlOJfaSsaQQx-UR1mWde_tuwTrOZgKVhJ2yNgZ10vpz0UIIN028VFM6vUBysE_Ufio6A7nGB89r7xu8SiVNll_JG5ejRejc7_uniW_K4DoJmW853OyVPEa8sZFZEjl_kjeQFL_j9DmeaA=s64","userId":"17547825594365273093"}},"outputId":"4f6c4c46-9e5b-4a95-fbb3-4d81a4b513b0"},"source":["results.keys()"],"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['passage_question_attention', 'span_start_logits', 'span_start_probs', 'span_end_logits', 'span_end_probs', 'best_span', 'best_span_str', 'question_tokens', 'passage_tokens', 'token_offsets'])"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","metadata":{"id":"pWz0sDdy01G0"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2K8EZ1-Sqgtj","executionInfo":{"status":"ok","timestamp":1638023649944,"user_tz":-180,"elapsed":629,"user":{"displayName":"Ahmet Melek","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWk81Nf32Tf0d0Jd6FX00TlioZ89O4UvaQrXdDOF6rUjBLzllwxAMrqh7j_piGK3NZPNt8c943aizmixPIoJNMqmMXgONFthAtwewKLJkeB6TozbkGlSGdH-1yU4E5VnpIA_-S5-N8eF2kk60G8SbMfmKTy0N1dZU6_1-j82cbTVyeiFgaGYukRi-Ul8Ve-TDOYROSzLMODA5YBkToostv-ChNd2IxX_faPKi4Rbk_FEaltxOILTkejo_6jd5y6uHC9LbIdpHKyILCt6fSJVSdiPOlEsHuFn-gv_2cF18K6zcjZrmv-GHM1GpaACBRr_-rBTRa-SZzrfflh24eI1f_DFT8G04K_dcqBE1nQIBgROvfGHaXSqhRXf3TFCTtB2RNnnNyNxADSuv5VnK51HAebBT8WZ4d_YZOgnQorLQEjEuCEBZgRZIn22AyaTNNEgrVvpKjEhiz6aAwCQ0xCQBDiHCVaNR6Q-X2yC2Q7WMTvppUp1Ik0sR8eC1mJBb94LObDGwZoaSMkuxm08Gsu6w_Wseg4gHgcH0jkWmNq0sEYGDea6SoY5vVCy9h_fVnWJOr-C_Il53t9qcsf0Hoq5tTpWGdryp4mB2vbGGb27ju3Tug8U64cLbEzAlOJfaSsaQQx-UR1mWde_tuwTrOZgKVhJ2yNgZ10vpz0UIIN028VFM6vUBysE_Ufio6A7nGB89r7xu8SiVNll_JG5ejRejc7_uniW_K4DoJmW853OyVPEa8sZFZEjl_kjeQFL_j9DmeaA=s64","userId":"17547825594365273093"}},"outputId":"cbb92f98-a89a-4ce2-fa3b-b5669e4a1453"},"source":["print(' '.join(results['passage_tokens']), ' '.join(results['question_tokens']), results['best_span_stys(r'], sep = '\\n\\n')"],"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["The Matrix is a 1999 science fiction action film written and directed by The Wachowskis , starring Keanu Reeves , Laurence Fishburne , Carrie - Anne Moss , Hugo Weaving , and Joe Pantoliano .\n","\n","What was the budget of The Matrix ?\n","\n","1999\n"]}]},{"cell_type":"markdown","metadata":{"tags":[],"id":"8_bdGooHnsgf"},"source":["### b- Named Entity Recognition (Tagging, Entity Extraction)\n"]},{"cell_type":"markdown","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[],"id":"LXrzGcwansgg"},"source":["Entity recognition is the task of extracting particular spans from text, and sometimes classifying them to classes like *Person* , *Location* , *Orgazination* etc.\n","\n","![NER.jpg](attachment:5be6d8ee-f937-437d-983d-7af7a2423618.jpg)\n","\n","In the image, we see an input sentence with 4 input words. NER Model takes the input, and assigns an output class for each token. In this example, outputs are:\n","- inzva -> Organization\n","- is -> None\n","- in -> None\n","- Beykoz -> Location\n","\n","Normally, tokens would be subwords, instead of words. In our example we consider words as tokens for simplicity."]},{"cell_type":"markdown","metadata":{"id":"M-wWGAB7nsgh"},"source":["To start getting predictions on NER, we import the tagging model from AllenNLP"]},{"cell_type":"code","metadata":{"id":"1iZboO_dnsgh"},"source":["import allennlp_models.tagging"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"98vbE1Ggnsgh"},"source":["We again create a Predictor instance, which will be our model."]},{"cell_type":"code","metadata":{"id":"d8oD5Qconsgh"},"source":["ner_model = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/ner-model-2020.02.10.tar.gz\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n3qMk890nsgi"},"source":["The model makes a prediction."]},{"cell_type":"code","metadata":{"id":"_mZ8N-P-nsgi","executionInfo":{"status":"ok","timestamp":1638023234287,"user_tz":-180,"elapsed":1856,"user":{"displayName":"Ahmet Melek","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWk81Nf32Tf0d0Jd6FX00TlioZ89O4UvaQrXdDOF6rUjBLzllwxAMrqh7j_piGK3NZPNt8c943aizmixPIoJNMqmMXgONFthAtwewKLJkeB6TozbkGlSGdH-1yU4E5VnpIA_-S5-N8eF2kk60G8SbMfmKTy0N1dZU6_1-j82cbTVyeiFgaGYukRi-Ul8Ve-TDOYROSzLMODA5YBkToostv-ChNd2IxX_faPKi4Rbk_FEaltxOILTkejo_6jd5y6uHC9LbIdpHKyILCt6fSJVSdiPOlEsHuFn-gv_2cF18K6zcjZrmv-GHM1GpaACBRr_-rBTRa-SZzrfflh24eI1f_DFT8G04K_dcqBE1nQIBgROvfGHaXSqhRXf3TFCTtB2RNnnNyNxADSuv5VnK51HAebBT8WZ4d_YZOgnQorLQEjEuCEBZgRZIn22AyaTNNEgrVvpKjEhiz6aAwCQ0xCQBDiHCVaNR6Q-X2yC2Q7WMTvppUp1Ik0sR8eC1mJBb94LObDGwZoaSMkuxm08Gsu6w_Wseg4gHgcH0jkWmNq0sEYGDea6SoY5vVCy9h_fVnWJOr-C_Il53t9qcsf0Hoq5tTpWGdryp4mB2vbGGb27ju3Tug8U64cLbEzAlOJfaSsaQQx-UR1mWde_tuwTrOZgKVhJ2yNgZ10vpz0UIIN028VFM6vUBysE_Ufio6A7nGB89r7xu8SiVNll_JG5ejRejc7_uniW_K4DoJmW853OyVPEa8sZFZEjl_kjeQFL_j9DmeaA=s64","userId":"17547825594365273093"}}},"source":["results = ner_model.predict(\n","  sentence=\"Google was founded on September 4, 1998, by Larry Page and Sergey Brin while they were Ph.D. students at Stanford University in California.\")"],"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xTK0M6Cwnsgi"},"source":["We examine the prediction, looking at its keys."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-vmONILBnsgj","executionInfo":{"status":"ok","timestamp":1638023242680,"user_tz":-180,"elapsed":313,"user":{"displayName":"Ahmet Melek","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWk81Nf32Tf0d0Jd6FX00TlioZ89O4UvaQrXdDOF6rUjBLzllwxAMrqh7j_piGK3NZPNt8c943aizmixPIoJNMqmMXgONFthAtwewKLJkeB6TozbkGlSGdH-1yU4E5VnpIA_-S5-N8eF2kk60G8SbMfmKTy0N1dZU6_1-j82cbTVyeiFgaGYukRi-Ul8Ve-TDOYROSzLMODA5YBkToostv-ChNd2IxX_faPKi4Rbk_FEaltxOILTkejo_6jd5y6uHC9LbIdpHKyILCt6fSJVSdiPOlEsHuFn-gv_2cF18K6zcjZrmv-GHM1GpaACBRr_-rBTRa-SZzrfflh24eI1f_DFT8G04K_dcqBE1nQIBgROvfGHaXSqhRXf3TFCTtB2RNnnNyNxADSuv5VnK51HAebBT8WZ4d_YZOgnQorLQEjEuCEBZgRZIn22AyaTNNEgrVvpKjEhiz6aAwCQ0xCQBDiHCVaNR6Q-X2yC2Q7WMTvppUp1Ik0sR8eC1mJBb94LObDGwZoaSMkuxm08Gsu6w_Wseg4gHgcH0jkWmNq0sEYGDea6SoY5vVCy9h_fVnWJOr-C_Il53t9qcsf0Hoq5tTpWGdryp4mB2vbGGb27ju3Tug8U64cLbEzAlOJfaSsaQQx-UR1mWde_tuwTrOZgKVhJ2yNgZ10vpz0UIIN028VFM6vUBysE_Ufio6A7nGB89r7xu8SiVNll_JG5ejRejc7_uniW_K4DoJmW853OyVPEa8sZFZEjl_kjeQFL_j9DmeaA=s64","userId":"17547825594365273093"}},"outputId":"177aa365-7222-4887-cfc4-65adfffe1a11"},"source":["results.keys()"],"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['logits', 'mask', 'tags', 'words'])"]},"metadata":{},"execution_count":30}]},{"cell_type":"markdown","metadata":{"id":"Wgvc2-J0nsgj"},"source":["We see that \"words\" and \"tags\" keys might be relevant to print out each word with their found class. So we print those lists."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"__x2SZIjnsgj","executionInfo":{"status":"ok","timestamp":1638023250690,"user_tz":-180,"elapsed":318,"user":{"displayName":"Ahmet Melek","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWk81Nf32Tf0d0Jd6FX00TlioZ89O4UvaQrXdDOF6rUjBLzllwxAMrqh7j_piGK3NZPNt8c943aizmixPIoJNMqmMXgONFthAtwewKLJkeB6TozbkGlSGdH-1yU4E5VnpIA_-S5-N8eF2kk60G8SbMfmKTy0N1dZU6_1-j82cbTVyeiFgaGYukRi-Ul8Ve-TDOYROSzLMODA5YBkToostv-ChNd2IxX_faPKi4Rbk_FEaltxOILTkejo_6jd5y6uHC9LbIdpHKyILCt6fSJVSdiPOlEsHuFn-gv_2cF18K6zcjZrmv-GHM1GpaACBRr_-rBTRa-SZzrfflh24eI1f_DFT8G04K_dcqBE1nQIBgROvfGHaXSqhRXf3TFCTtB2RNnnNyNxADSuv5VnK51HAebBT8WZ4d_YZOgnQorLQEjEuCEBZgRZIn22AyaTNNEgrVvpKjEhiz6aAwCQ0xCQBDiHCVaNR6Q-X2yC2Q7WMTvppUp1Ik0sR8eC1mJBb94LObDGwZoaSMkuxm08Gsu6w_Wseg4gHgcH0jkWmNq0sEYGDea6SoY5vVCy9h_fVnWJOr-C_Il53t9qcsf0Hoq5tTpWGdryp4mB2vbGGb27ju3Tug8U64cLbEzAlOJfaSsaQQx-UR1mWde_tuwTrOZgKVhJ2yNgZ10vpz0UIIN028VFM6vUBysE_Ufio6A7nGB89r7xu8SiVNll_JG5ejRejc7_uniW_K4DoJmW853OyVPEa8sZFZEjl_kjeQFL_j9DmeaA=s64","userId":"17547825594365273093"}},"outputId":"34f54229-4d61-49b0-abb2-ef483cae5415"},"source":["for word, tag in zip(results[\"words\"], results[\"tags\"]):\n","    print(f\"{word}\\t{tag}\")"],"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Google\tU-ORG\n","was\tO\n","founded\tO\n","on\tO\n","September\tO\n","4\tO\n",",\tO\n","1998\tO\n",",\tO\n","by\tO\n","Larry\tB-PER\n","Page\tL-PER\n","and\tO\n","Sergey\tB-PER\n","Brin\tL-PER\n","while\tO\n","they\tO\n","were\tO\n","Ph.D.\tU-MISC\n","students\tO\n","at\tO\n","Stanford\tB-ORG\n","University\tL-ORG\n","in\tO\n","California\tU-LOC\n",".\tO\n"]}]},{"cell_type":"markdown","metadata":{"tags":[],"id":"icxsqkMansgj"},"source":["### c- Sentiment Analysis"]},{"cell_type":"markdown","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[],"id":"VUlfC7innsgk"},"source":["Sentiment Analysis is a text classification problem. One of the easiest ways to do it is to classify the text either as postive or negative.\n","\n","![Sentiment Analysis(2).jpg](attachment:71209240-7a14-4ed3-97d4-8bc5ba5720f2.jpg)\n","\n","In the example we see that the person thinks that the movie sucks (is bad). \n","\n","This is because the person states that if they said the movie *didn't* suck, it would be a *lie* (this is a double negation example)."]},{"cell_type":"markdown","metadata":{"id":"CR8uZRuCnsgk"},"source":["We import the classification module since the way that we model sentiment analysis is a classification problem."]},{"cell_type":"code","metadata":{"id":"7q_ABmf3nsgk"},"source":["import allennlp_models.classification"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MmAqA8dCnsgl"},"source":["We start a predictor class witht the pretrained sentiment analysis model's path."]},{"cell_type":"code","metadata":{"id":"QThs6x4mnsgl"},"source":["sentiment_classifier = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/basic_stanford_sentiment_treebank-2020.06.09.tar.gz\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uiQK3w6Qnsgl"},"source":["We write a negative review."]},{"cell_type":"code","metadata":{"id":"ZUhC7fytnsgm","executionInfo":{"status":"ok","timestamp":1638024061582,"user_tz":-180,"elapsed":354,"user":{"displayName":"Ahmet Melek","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWk81Nf32Tf0d0Jd6FX00TlioZ89O4UvaQrXdDOF6rUjBLzllwxAMrqh7j_piGK3NZPNt8c943aizmixPIoJNMqmMXgONFthAtwewKLJkeB6TozbkGlSGdH-1yU4E5VnpIA_-S5-N8eF2kk60G8SbMfmKTy0N1dZU6_1-j82cbTVyeiFgaGYukRi-Ul8Ve-TDOYROSzLMODA5YBkToostv-ChNd2IxX_faPKi4Rbk_FEaltxOILTkejo_6jd5y6uHC9LbIdpHKyILCt6fSJVSdiPOlEsHuFn-gv_2cF18K6zcjZrmv-GHM1GpaACBRr_-rBTRa-SZzrfflh24eI1f_DFT8G04K_dcqBE1nQIBgROvfGHaXSqhRXf3TFCTtB2RNnnNyNxADSuv5VnK51HAebBT8WZ4d_YZOgnQorLQEjEuCEBZgRZIn22AyaTNNEgrVvpKjEhiz6aAwCQ0xCQBDiHCVaNR6Q-X2yC2Q7WMTvppUp1Ik0sR8eC1mJBb94LObDGwZoaSMkuxm08Gsu6w_Wseg4gHgcH0jkWmNq0sEYGDea6SoY5vVCy9h_fVnWJOr-C_Il53t9qcsf0Hoq5tTpWGdryp4mB2vbGGb27ju3Tug8U64cLbEzAlOJfaSsaQQx-UR1mWde_tuwTrOZgKVhJ2yNgZ10vpz0UIIN028VFM6vUBysE_Ufio6A7nGB89r7xu8SiVNll_JG5ejRejc7_uniW_K4DoJmW853OyVPEa8sZFZEjl_kjeQFL_j9DmeaA=s64","userId":"17547825594365273093"}}},"source":["# Review of the movie \"Joker\" on Rotten Tomatoes\n","review = \"Begenmedim ben bu filmi\""],"execution_count":62,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9e5bXjSJnsgn"},"source":["We forward our negative review to the model."]},{"cell_type":"code","metadata":{"id":"l9sYijZznsgn","executionInfo":{"status":"ok","timestamp":1638024062619,"user_tz":-180,"elapsed":8,"user":{"displayName":"Ahmet Melek","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWk81Nf32Tf0d0Jd6FX00TlioZ89O4UvaQrXdDOF6rUjBLzllwxAMrqh7j_piGK3NZPNt8c943aizmixPIoJNMqmMXgONFthAtwewKLJkeB6TozbkGlSGdH-1yU4E5VnpIA_-S5-N8eF2kk60G8SbMfmKTy0N1dZU6_1-j82cbTVyeiFgaGYukRi-Ul8Ve-TDOYROSzLMODA5YBkToostv-ChNd2IxX_faPKi4Rbk_FEaltxOILTkejo_6jd5y6uHC9LbIdpHKyILCt6fSJVSdiPOlEsHuFn-gv_2cF18K6zcjZrmv-GHM1GpaACBRr_-rBTRa-SZzrfflh24eI1f_DFT8G04K_dcqBE1nQIBgROvfGHaXSqhRXf3TFCTtB2RNnnNyNxADSuv5VnK51HAebBT8WZ4d_YZOgnQorLQEjEuCEBZgRZIn22AyaTNNEgrVvpKjEhiz6aAwCQ0xCQBDiHCVaNR6Q-X2yC2Q7WMTvppUp1Ik0sR8eC1mJBb94LObDGwZoaSMkuxm08Gsu6w_Wseg4gHgcH0jkWmNq0sEYGDea6SoY5vVCy9h_fVnWJOr-C_Il53t9qcsf0Hoq5tTpWGdryp4mB2vbGGb27ju3Tug8U64cLbEzAlOJfaSsaQQx-UR1mWde_tuwTrOZgKVhJ2yNgZ10vpz0UIIN028VFM6vUBysE_Ufio6A7nGB89r7xu8SiVNll_JG5ejRejc7_uniW_K4DoJmW853OyVPEa8sZFZEjl_kjeQFL_j9DmeaA=s64","userId":"17547825594365273093"}}},"source":["result = sentiment_classifier.predict(sentence=review)"],"execution_count":63,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R_nq33jUnsgn"},"source":["We print \"positive\" if the model's confidence is higher on being positive than negative. \n","\n","Notice that AllenNLP models the sentiment analysis task in a more complex way than binary classification. \n","\n","They have multiple classes and also confidence values associated with each class."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"INqyF3l-nsgo","executionInfo":{"status":"ok","timestamp":1638024063708,"user_tz":-180,"elapsed":16,"user":{"displayName":"Ahmet Melek","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWk81Nf32Tf0d0Jd6FX00TlioZ89O4UvaQrXdDOF6rUjBLzllwxAMrqh7j_piGK3NZPNt8c943aizmixPIoJNMqmMXgONFthAtwewKLJkeB6TozbkGlSGdH-1yU4E5VnpIA_-S5-N8eF2kk60G8SbMfmKTy0N1dZU6_1-j82cbTVyeiFgaGYukRi-Ul8Ve-TDOYROSzLMODA5YBkToostv-ChNd2IxX_faPKi4Rbk_FEaltxOILTkejo_6jd5y6uHC9LbIdpHKyILCt6fSJVSdiPOlEsHuFn-gv_2cF18K6zcjZrmv-GHM1GpaACBRr_-rBTRa-SZzrfflh24eI1f_DFT8G04K_dcqBE1nQIBgROvfGHaXSqhRXf3TFCTtB2RNnnNyNxADSuv5VnK51HAebBT8WZ4d_YZOgnQorLQEjEuCEBZgRZIn22AyaTNNEgrVvpKjEhiz6aAwCQ0xCQBDiHCVaNR6Q-X2yC2Q7WMTvppUp1Ik0sR8eC1mJBb94LObDGwZoaSMkuxm08Gsu6w_Wseg4gHgcH0jkWmNq0sEYGDea6SoY5vVCy9h_fVnWJOr-C_Il53t9qcsf0Hoq5tTpWGdryp4mB2vbGGb27ju3Tug8U64cLbEzAlOJfaSsaQQx-UR1mWde_tuwTrOZgKVhJ2yNgZ10vpz0UIIN028VFM6vUBysE_Ufio6A7nGB89r7xu8SiVNll_JG5ejRejc7_uniW_K4DoJmW853OyVPEa8sZFZEjl_kjeQFL_j9DmeaA=s64","userId":"17547825594365273093"}},"outputId":"9a362ad3-e920-4da5-cd51-912ad57e1d36"},"source":["print('Positive with confidence of', result['probs'][0]) if result['label']=='1' else print('Negative with confidence of', result['probs'][1])"],"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["Positive with confidence of 0.9953984618186951\n"]}]},{"cell_type":"markdown","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[],"id":"LgbLXx4Xnsgo"},"source":["## 2- Using Huggingface Transformers\n","\n","Transformers is an open source NLP framework formed by Huggingface, a private company & community.\n","\n","![image.png](attachment:d93e6329-539b-4fb4-a4e0-0c0da8e66c13.png)\n","\n","Note: You can also check https://huggingface.co/spaces to get a wider sense on NLP (and also other machine learning) tasks. "]},{"cell_type":"markdown","metadata":{"id":"hBgKKNa5nsgo"},"source":["____"]},{"cell_type":"markdown","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[],"id":"wqyp4aplnsgo"},"source":["### Using \"Pipeline\" for Sentiment Analysis"]},{"cell_type":"markdown","metadata":{"id":"TClts5AWnsgp"},"source":["Pipeline class is a wrapper in Huggingface, just like the Predictor in AllenNLP. \n","\n","It basically creates a more specialized class instance under the hood, based on the task name that you give. "]},{"cell_type":"markdown","metadata":{"tags":[],"id":"Q2pS6vlXnsgp"},"source":["Sentiment Analysis is a text classification problem. One of the easiest ways to do it is to classify the text either as postive or negative.\n","\n","![Sentiment Analysis(2).jpg](attachment:71209240-7a14-4ed3-97d4-8bc5ba5720f2.jpg)\n","\n","In the example we see that the person thinks that the movie sucks (is bad). \n","\n","This is because the person states that if they said the movie *didn't* suck, it would be a *lie* (this is a double negation example)."]},{"cell_type":"code","metadata":{"id":"V9Ikp9Nhnsgp"},"source":["# Have either PyTorch >= 1.1 or TensorFlow >= 2.0. Then run the following command to install HuggingFace:\n","!pip install transformers"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q-snsV0Vnsgp"},"source":["We start a Pipeline instance, particularly, a sentiment analysis pipeline. \n","\n","Right after we create it, we forward an input to it. The input is \"we love you\"."]},{"cell_type":"code","metadata":{"id":"ezqrdOPvnsgp"},"source":["from transformers import pipeline\n","\n","print(pipeline('sentiment-analysis')('we love you'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[],"id":"l7jMrYhYnsgq"},"source":["### Using \"Pipeline\" for Question Answering"]},{"cell_type":"markdown","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[],"id":"0DELFanmnsgq"},"source":["Question answering is the task of extracting text spans from context paragraphs. While doing the extraction model also takes a question into account.\n","\n","- Inputs: Context Paragraph (tokenized string), Question (tokenized string)\n","- Outputs: A text span (de-tokenized list of tokens), named as the \"Answer\"\n","- Popular Methods: BERT based QA models\n","\n","![QA.jpg](attachment:e040814c-2db4-4b88-9a40-2370a67eaead.jpg)\n","\n","In the example, we see a context paragraph, giving information on inzva. Then, we have a question, asking inzva's foundation date.\n","\n","We basically ask the model this question: \n","\n","- **If we have N tokens in the context, what is the likelihood of $n^{\\text{th}}$ token to be the start token of the answer. Likewise, what is the likelihood for each token to be the ending token of the answer?**\n","- By asking that, we find the most likely start and end positions for the answer span.\n","- Then we can get the answer span between the most likely start token and the most likely end token. \n","- In the example, token \"2017\" is the most likely token to be the start token. It is also most likely to be the end token. Between the most likely start token and the most likely end token, the only word is \"2017\" so we take that as the answer.\n","\n","___"]},{"cell_type":"markdown","metadata":{"id":"hC3fJbu8nsgr"},"source":["We start a QA pipeline, and name it as \"nlp\". \n","\n","We also define one of our inputs (the context). It is an informative paragraph on one of the subtopics of Machine Learning. "]},{"cell_type":"code","metadata":{"id":"s2FwYftGnsgr"},"source":["nlp = pipeline(\"question-answering\")\n","\n","context = r\"\"\"\n","Extractive Question Answering is the task of extracting an answer from a text given a question. An example of a\n","question answering dataset is the SQuAD dataset, which is entirely based on that task. If you would like to fine-tune\n","a model on a SQuAD task, you may leverage the examples/question-answering/run_squad.py script.\n","\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ptXBor4qnsgs"},"source":["We define the other part of our input (the question). It is a question about one of the subtopics in Machine Learning.\n","\n","We can ask multiple questions for the same context paragraph, and vice versa in certain cases. For that, we ask another question.\n","\n","We print: \n","- the answer span\n","- the score for the answer (similar to confidence, but not a probability value)\n","- the location (index) of the start of the answer\n","- the location of the end of the answer "]},{"cell_type":"code","metadata":{"id":"51AfgoNvnsgs"},"source":["result = nlp(question=\"What is extractive question answering?\", context=context)\n","print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")\n","\n","result = nlp(question=\"What is a good example of a question answering dataset?\", context=context)\n","print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"tags":[],"id":"Ptn4PoV6nsgs"},"source":["### Text Generation with GPT-2"]},{"cell_type":"markdown","metadata":{"id":"rxk0AdYJnsgt"},"source":["- Text Generation is essentially a language modelling task, however, lately it has started to become more.\n","\n","- Some text generation models (like GPT-2) can be fine-tuned to perform a huge variety of NLP tasks (QA, classification etc.). \n","\n","- Some newer text generation models (like GPT-3 and GPT-J) can even zero-shot a wider variety of tasks.\n","\n","![Untitled Diagram.jpg](attachment:0ae18278-ba30-4d2a-915a-6d9bb5d953b8.jpg)\n","\n","\n","In this example, the task solely Text Generation, similar to writing a story. We will start the story, and expect the model to write new lines. We will use GPT-2 due to practical limitations.\n","\n","We import specific GPT model and tokenizer classes to form our predictive system, then create tokenizer and model instances."]},{"cell_type":"code","metadata":{"id":"8bI2a3Ifnsgt"},"source":["# For this example, tensorflow >= 2.1 should be installed on the system\n","\n","import tensorflow as tf\n","from transformers import TFGPT2LMHeadModel, GPT2Tokenizer\n","\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","\n","# add the EOS token as PAD token to avoid warnings\n","model = TFGPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nBf3sR1lnsgt"},"source":["We tokenize the input sentence (the beginning of our story). You can examine the tokenized object if you want. "]},{"cell_type":"code","metadata":{"id":"qPgtpn3Tnsgt"},"source":["# encode context the generation is conditioned on\n","input_ids = tokenizer.encode('I enjoy walking with my cute dog', return_tensors='tf')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7fJZ8kC0nsgu"},"source":["We generate the continuation of our story. Our arguments specify:\n","- max_length=50: do not generate more than 50 tokens\n","- num_beams=5: when you are thinking about the best possible stories, do not think about more than 5 stories at the same time.\n","- no_repeat_ngram_size=2: ?\n","- early_stopping=True: ?\n","\n","We get the output (it is a list of tokens) then we join all of them to get one string."]},{"cell_type":"code","metadata":{"id":"N5iTJ5r-nsgu"},"source":["beam_output = model.generate(\n","    input_ids, \n","    max_length=50, \n","    num_beams=5, \n","    no_repeat_ngram_size=2, \n","    early_stopping=True\n",")\n","\n","print(\"Output:\\n\" + 100 * '-')\n","print(tokenizer.decode(beam_output[0], skip_special_tokens=False))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xjOH8g2pnsgu"},"source":["### Conversational Agent\n","\n","Conversational Agents are multi-component systems that are engineered to act as Chatbots. They take action for various queries:\n","\n","- Order a pizza.\n","- Call my friend Suzie.\n","- What's the weather like today?\n","- ...\n","\n","In this example, we are trying out an end-to-end conversational agent, that is only designed for chitchat. \n","\n","It is a finetuned version of one of the GPT models, to do chitchat.\n","\n","![Untitled Diagram(1).jpg](attachment:0d8f087b-8cae-4231-ae1a-b40d12c6de4f.jpg)"]},{"cell_type":"code","metadata":{"id":"fECvvdek8yjR"},"source":["# intent recognition (text classification)\n","# response generation"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AbhArQ8unsgu"},"source":["from transformers import AutoModelForCausalLM, AutoTokenizer\n","import torch\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-large\")\n","model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-large\")\n","\n","# Let's chat for 5 lines\n","for step in range(5):\n","    # encode the new user input, add the eos_token and return a tensor in Pytorch\n","    new_user_input_ids = tokenizer.encode(input(\">> User:\") + tokenizer.eos_token, return_tensors='pt')\n","\n","    # append the new user input tokens to the chat history\n","    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n","\n","    # generated a response while limiting the total chat history to 1000 tokens, \n","    chat_history_ids = model.generate(bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n","\n","    # pretty print last ouput tokens from bot\n","    print(\"DialoGPT: {}\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3qD_e3Lbqvkm"},"source":["# Does money buy happiness?\n","# what is the meaning of life ?\n","# who is the first president of the United States\n","# which one is bigger, sun or moon?\n","# what is the boiling point of water?\n","# who won the world cup in 2018 ?\n","# Nvidia's Titan RTX is really good ."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"alhorov8rWVC"},"source":[""],"execution_count":null,"outputs":[]}]}