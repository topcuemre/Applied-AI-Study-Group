{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1: Introduction to Computer Vision\n",
    "\n",
    "## Notebook 2: Keypoint Localization with a Convolutional Neural Network using PyTorch\n",
    "\n",
    "Welcome to the second notebook of this week's Applied AI Study Group! We will study localization problem with [Facial Keypoints Dataset](https://www.kaggle.com/c/facial-keypoints-detection/data) provided by [Kaggle](https://www.kaggle.com/). The aim of our task will be to locate distinguishing points on human faces.\n",
    "\n",
    "### 1. Localization\n",
    "\n",
    "Localization is one of the core tasks of Computer Vision. In this task, we aim to find the locations of objects in the given data. Then, we indicate their position in various representations based on our task. For instance, if we are looking for dogs in given images, we represent their location with bounding boxes. In our case, we will locate the keypoints of human faces, hence, we will have (x, y) coordinate representation as output vectors. An example of localization task can be seen in the following image:\n",
    "\n",
    "![Localization example](./images/localization.png \"Example Localization\")\n",
    "\n",
    "### 2. Facial Keypoints Dataset\n",
    "\n",
    "Our dataset is provided by Kaggle. It consists of CSV files. Training data contains 7049 images. Each row of the CSV table contains (x, y) coordinates of 15 keypoints we want to detect per face, and input image as row-ordered list of pixels in the last column of each row. Examples of our dataset will be shown in upcoming code cells.\n",
    "\n",
    "The following first three code cells can be used to download facial keypoints dataset we will use for this notebook using Kaggle API.\n",
    "\n",
    "### 3. Imports and Checks\n",
    "\n",
    "You should have installed Numpy and Matplotlib using `pip` and, PyTorch using [Week 0 - Notebook 2](https://github.com/inzva/Applied-AI-Study-Group/blob/add-frameworks-week/Applied%20AI%20Study%20Group%20%236%20-%20January%202022/Week%200/2-mnist_classification_convnet_pytorch.ipynb).\n",
    "\n",
    "As we introduce first time today, you can install `pandas` via `pip` as well.\n",
    "\n",
    "    pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we already stated, the following first three code cells can be used to download facial keypoints dataset we will use for this notebook using Kaggle API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kaggle competitions download -c facial-keypoints-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# if keypoint dataset is unzipped\n",
    "#!unzip facial-keypoints-detection.zip\n",
    "#!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if training is unzipped\n",
    "#!unzip training.zip\n",
    "#!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using `Google Colab`, you can use the following commented line to import drive into this notebook in runtime. For further information: [Google Colab](https://colab.research.google.com/?utm_source=scs-index#scrollTo=GJBs_flRovLc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# from google.colab import drive\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the following cell runs successfully, then, you are good to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)\n",
    "print(pd.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We explore our dataset further in the following cell. First, we load our dataset using `Pandas`. Pandas is a great library dealing with `CSV` files. Then, we print the columns and the first 5 line of our dataset to check what our data looks like.\n",
    "\n",
    "In the third print line, we check if there is any `null` values in our dataset which may hurt our training in later phases. As a data preprocessing step, we utilize pandas function `fillna` to change these `null` values into the last valid observation we made. It is similar to nearest neighbor interpolation. For further information: [fiilna](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html).\n",
    "\n",
    "Then, we check if there is any `null` left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./datasets/facial_keypoints/training.csv')\n",
    "print(data.columns)\n",
    "print(data.head())\n",
    "print(data.isnull().any().value_counts())\n",
    "data.fillna(method = 'ffill',inplace = True)\n",
    "print(data.isnull().any().value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to `null` values, we may have empty image pixels in the given dataset. We fill those values with `0`, so that, we can iterate over our dataset without any type error or empty pixel error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_data = len(data)\n",
    "pixel_list = []\n",
    "for i in range(num_train_data):\n",
    "    row = data['Image'][i].split(' ')\n",
    "    pixel = ['0' if x == '' else x for x in row] # handling empty image pixels\n",
    "    pixel_list.append(pixel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `PyTorch`, the image data is represented by (B, C, W, H) where B = batch size, C = number of channels, W = width of the image, H = height of the image. In our case, the dataset is represented by (B, W, H, C). So, we need to swap the dimensions to properly process the data throughout our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Pytorch takes channels in the second dimension. For that, I swap axes (dimensions)\n",
    "image_tensor = np.array(pixel_list, dtype = 'float')\n",
    "print(np.shape(image_tensor))\n",
    "image_tensor = image_tensor.reshape(-1, 96, 96, 1)\n",
    "image_tensor = np.swapaxes(image_tensor, 2, 3)\n",
    "image_tensor = np.swapaxes(image_tensor, 1, 2)\n",
    "print(np.shape(image_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we separate our input data into the training image and training ground-truth data. To do that, we remove the `Image` column from our dataset, then, the columns left are human face keypoint coordinates which are ground-truths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data.drop('Image',axis = 1)\n",
    "\n",
    "label_list = []\n",
    "for i in range(num_train_data):\n",
    "    label = labels.iloc[i,:]\n",
    "    label_list.append(label)\n",
    "label_tensor = np.array(label_list,dtype = 'float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize some of them to understand what our task looks like. Also, to double-check if every processing we make so far is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import Circle\n",
    "\n",
    "index = random.randint(0,1000)\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "ax.imshow(image_tensor[index].reshape(96,96),cmap='gray')\n",
    "\n",
    "for xx, yy in label_tensor[index].reshape((15,2)):\n",
    "    circ = Circle((xx,yy),2,color='red')\n",
    "    ax.add_patch(circ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will not upload our model into the `Kaggle`, we separate some of our training images into the another set. Because we will use them as our test images. Then, we create our dataloaders for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = 6000\n",
    "img_and_label = []\n",
    "for i in range(train_len):\n",
    "    img_and_label.append([image_tensor[i], label_tensor[i]])\n",
    "\n",
    "# we use Dataloader objects in pytorch to easily iterate on our dataset while performing training loops\n",
    "train_loader = torch.utils.data.DataLoader(img_and_label, shuffle=True, batch_size=500)\n",
    "img1, lbl1 = next(iter(train_loader))\n",
    "print(\"first training batch: \\n\" + \"input shape: \" + str(img1.shape) + \"\\n\" + \"label shape: \" + str(lbl1.shape))\n",
    "\n",
    "test_data = []\n",
    "for i in range(train_len, num_train_data): # since we have no labels for real test data!\n",
    "    test_data.append([image_tensor[i], label_tensor[i]])\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_data, shuffle=True, batch_size=500)\n",
    "test1, tlbl1 = next(iter(test_loader))\n",
    "print(\"test batch: \\n\" + \"input shape: \" + str(test1.shape) + \"\\n\" + \"label shape: \" + str(tlbl1.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using PyTorch, we build our model in the following cell. Our model consists of 2D Convolution filters, Max pooling, Batch Normalization layers and Leaky ReLU as our activation function in the phase of feature extraction. Then, we utilize Linear layers, 1D Batch normalization, and Sigmoid activation function for further keypoint regression. Be careful that we do not use sigmoid layer in the final layer since we want to regress exact positions but not [0, 1] projected coordinates. Also, we flatten our mid-layer feature vector while we move forward from 2D feature extraction stage to 1D regression stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# we write our networks as class instances. dont forget to inherit from nn.Module\n",
    "class Net(nn.Module):\n",
    "    # we always need an init method to define our output matrices (similar to nodes in graph)\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.leaky_relu = nn.LeakyReLU(0.1)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 32, 5) #1, 32\n",
    "        self.conv1_bn = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, 5) #32, 64\n",
    "        self.conv2_bn = nn.BatchNorm2d(64)\n",
    "\n",
    "        #self.conv3 = nn.Conv2d(16, 32, 5) #64, 128\n",
    "        #self.conv3_bn = nn.BatchNorm2d(32)\n",
    "\n",
    "        #self.conv4 = nn.Conv2d(32, 64, 5) #128, 256\n",
    "        #self.conv4_bn = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.fc1 = nn.Linear(64 * 21 * 21, 120)\n",
    "        self.fc1_bn = nn.BatchNorm1d(120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc2_bn = nn.BatchNorm1d(84)\n",
    "        self.fc3 = nn.Linear(84, 30)\n",
    "        \n",
    "    # we always need an forward method to draw our computational graph (similar to completing the graph with edges)\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.max_pool(self.leaky_relu(self.conv1_bn(self.conv1(x))))\n",
    "        x = self.max_pool(self.leaky_relu(self.conv2_bn(self.conv2(x))))\n",
    "        #x = self.leaky_relu(self.conv3_bn(self.conv3(x)))\n",
    "        #x = self.max_pool(self.leaky_relu(self.conv4_bn(self.conv4(x))))\n",
    "\n",
    "        # vectorize (flatten)\n",
    "        x = x.reshape(-1, 64 * 21 * 21)\n",
    "        #x = torch.flatten(x)\n",
    "        #x = torch.reshape(x, (input_shape, -1))\n",
    "        x = torch.sigmoid(self.fc1_bn(self.fc1(x)))        \n",
    "        x = torch.sigmoid(self.fc2_bn(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "inzvaNet = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify our loss function, optimizer, and the number of epochs we will train our model in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(inzvaNet.parameters(), lr=0.0001, momentum=0.9)\n",
    "num_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inzvaNet = inzvaNet.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We switch from CPU to GPU if we have any available GPU devices. It will bring a huge increase in inference time for our model training. \n",
    "\n",
    "Note: Without GPU, it will take much time to train this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we get info on our gpu, put it in the variable \"device\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)\n",
    "\n",
    "#we carry our model into gpu\n",
    "inzvaNet.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we will initiate our training loop. We iterate through our dataset and update our model. Also, we can observe the improvement of our model with a decrease in the loss values throughout the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our training loop\n",
    "# check for free memory option -> this code may lead to memory explosion if grads are not cleared, etc.\n",
    "for epoch in range(num_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # here we use the dataloader object. it performs .next() operation in each iteration of the loop\n",
    "    # we also group our batches with numbers. we do this with enumerate. we do this so we can know in which batch we are \n",
    "    for i, data in enumerate(train_loader, start = 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "\n",
    "        #inputs, labels = data\n",
    "        inputs, labels = data[0].float().to(device), data[1].float().to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = inzvaNet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 0:    # print every 2000 mini-batches\n",
    "            print('Epoch %d Loss: %.3f' %\n",
    "                  (epoch + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will test our trained model, so that, we can have a better understanding where our model fails and where our model performs better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_test = random.randint(0,49)\n",
    "test_batch = next(iter(test_loader))\n",
    "\n",
    "test_batch_data = test_batch[0].float().to(device)\n",
    "test_batch_label = test_batch[1].float().to(device)\n",
    "\n",
    "preds = inzvaNet(test_batch_data).cpu()\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "ax.imshow(test_batch_data[rand_test].cpu().view((96,96)), cmap = 'gray')\n",
    "\n",
    "for xx, yy in preds[rand_test].reshape((15,2)):\n",
    "    circ = Circle((xx, yy), 2, color='red')\n",
    "    ax.add_patch(circ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "ax.set_aspect('equal')\n",
    "ax.imshow(test_batch_data[rand_test].cpu().view((96,96)), cmap = 'gray')\n",
    "\n",
    "for xx, yy in test_batch_label[rand_test].reshape((15,2)):\n",
    "    circ = Circle((xx, yy), 2, color='red')\n",
    "    ax.add_patch(circ)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
