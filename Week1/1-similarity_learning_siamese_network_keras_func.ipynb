{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1: Introduction to Computer Vision\n",
    "\n",
    "## Notebook 1: Similarity Learning with a Siamese Neural Network using Keras Functional\n",
    "\n",
    "Welcome to the second week of Applied AI Study Group! We will work through a couple of crucial Computer Vision tasks with the commonly used frameworks and libraries this week.\n",
    "\n",
    "In the previous week, you tackled the simple classification tasks using Dense Neural Networks and Convolutional Neural Networks. Hence, you are already familiar with essential elements of Computer Vision models we are going to build today.\n",
    "\n",
    "In this notebook, we are starting our journey of Computer Vision tasks with Siamese Neural Networks to learn Similarity. \n",
    "\n",
    "This notebook is prepared using the following three sources: [PyImageSearch 1](https://www.pyimagesearch.com/2020/11/23/building-image-pairs-for-siamese-networks-with-python/), [PyImageSearch 2](https://www.pyimagesearch.com/2020/11/30/siamese-networks-with-keras-tensorflow-and-deep-learning/), and [PyImageSearch 3](https://www.pyimagesearch.com/2020/12/07/comparing-images-for-similarity-using-siamese-networks-keras-and-tensorflow/).\n",
    "\n",
    "### 1. Similarity Learning\n",
    "\n",
    "Why do we need learning similarity? Would not be enough if we have a classification model that predicts whether an input belongs a category or not? \n",
    "\n",
    "The answer is no. Because it would not scale well to new categories added to the dataset we have. Let's consider case: we train a model for recognizing employees in a company's entrance to allow them to go into the building. For instance, we have 100 different employees and our model can successfully recognize them. What happens someone leave or another people join to the company? We would need a couple of images and train our model again and again for each case every time. The thing is we do not need to know whom we are recognizing, right? We just need to know that that person is in our employee list. So, it is better to train a model that differentiates whether that person is in our company or not. For this case, we would just need to measure similarity between the image we have for that employee and the person in the entrance to decide.\n",
    "\n",
    "Now, we know why we need similarity learning. The next question is how we can design a model and training schemas to perform our task successfully. Since we do not need which category or which humanbeing we are recognizing, we do not need to have labels of all objects we have. We just need to differentiate whether two things are same or not. Hence, we can intuitively think this would be a binary classification task in which the output of our model will be whether the same or not, hence 0 or 1. We know what our output will be, then, the question will be what we are going to learn? \n",
    "\n",
    "We will learn a similarity function that returns a low similarity score for two instances belong to the different classes, high otherwise. Then, we can set a threshold to decide whether they belong to the same or not. Finally, having almost everything in our task decided, we just need to figure out what our model will be like to successfully reach a high-accuracy model. We will design a siamese neural network in which we will talk about in the next section.\n",
    "\n",
    "### 2. Siamese Neural Networks\n",
    "\n",
    "Siamese Neural Networks are specialized for comparing two different input vectors. The reason we call this type of networks as Siamese (also called twin) is we use the same set of (shared weights) layers to process given inputs. After the processing of input vectors, we compare the extracted representations to decide whether inputs are similar or not. To do that, we can define distance functions such as euclidean.\n",
    "\n",
    "![Siamese Neural Network Model Architecture](./images/siamese_nn.png \"Example Siamese Neural Network\")\n",
    "\n",
    "### 3. Installation\n",
    "\n",
    "As in the previous Starter Week 0, we will use Python together with Jupyter to go through all our notebooks. If you had not installed the required packages to run these notebooks today, please go to the [Week 0 - Notebook 1](https://github.com/inzva/Applied-AI-Study-Group/blob/add-frameworks-week/Applied%20AI%20Study%20Group%20%236%20-%20January%202022/Week%200/1-mnist_classification_dense_tensorflow2.ipynb) and follow the instructions for all requirements.\n",
    "\n",
    "### 4. Imports and Checks\n",
    "\n",
    "Also, for installing necessary packages, please use the following instructions:\n",
    "\n",
    "For tensorflow, you can follow the previous week's instructions: [Week 0 - Notebook 1](https://github.com/inzva/Applied-AI-Study-Group/blob/add-frameworks-week/Applied%20AI%20Study%20Group%20%236%20-%20January%202022/Week%200/1-mnist_classification_dense_tensorflow2.ipynb)\n",
    "\n",
    "Keras is already installed with Tensorflow 2.\n",
    "\n",
    "Below we import the necessary libraries for data exploration and some further data operations. If any of these packages are not installed on your system, please install them via `pip` or `conda`:\n",
    "\n",
    "For cv2 case, please use the following: \n",
    "\n",
    "    pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow as tf\n",
    "from imutils import build_montages\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will use `Keras Datasets` to load `MNIST` dataset. We can also directly separate data into train and test sets with training data and ground-truth data. For API reference: [Keras Datasets](https://keras.io/api/datasets/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, trainY), (testX, testY) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to have input pairs for training our model. Because we will learn to measure similarity, not classify the input data. Hence, we need to process our dataset to have pairs with their corresponding labels. For the input images belonging to same classes we will have label 1, and 0 otherwise. The following function aims to create pairs from given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pairs(images, labels):\n",
    "    pairImages=[]\n",
    "    pairLabels=[]\n",
    "    numClasses = len(np.unique(labels))\n",
    "    idx = [np.where(labels == i)[0] for i in range(0, numClasses)]\n",
    "    for i in range(0, numClasses):\n",
    "        idxs = np.where(labels == i)[0]\n",
    "        print(\"{}: {} {}\".format(i, len(idxs), idxs))\n",
    "    for idxA in range(len(images)):\n",
    "        currentImage = images[idxA]\n",
    "        label = labels[idxA]\n",
    "        idxB = np.random.choice(idx[label])\n",
    "        posImage = images[idxB]\n",
    "        pairImages.append([currentImage, posImage])\n",
    "        pairLabels.append([1])\n",
    "        negIdx = np.where(labels != label)[0]\n",
    "        negImage = images[np.random.choice(negIdx)]\n",
    "        pairImages.append([currentImage, negImage])\n",
    "        pairLabels.append([0])\n",
    "    return (np.array(pairImages), np.array(pairLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call our function to have pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pairTrain_vis, labelTrain_vis) = make_pairs(trainX, trainY)\n",
    "(pairTest_vis, labelTest_vis) = make_pairs(testX, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize a small set of our dataset to observe what it looks like. In this loop, we randomly sample 49 pairs with their labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for i in np.random.choice(np.arange(0, len(pairTrain_vis)), size=(49,)):\n",
    "    # grab the current image pair and label\n",
    "    imageA = pairTrain_vis[i][0]\n",
    "    imageB = pairTrain_vis[i][1]\n",
    "    label = labelTrain_vis[i]\n",
    "    \n",
    "    output = np.zeros((36, 60), dtype=\"uint8\")\n",
    "    pair = np.hstack([imageA, imageB])\n",
    "    output[4:32, 0:56] = pair\n",
    "    \n",
    "    text = \"neg\" if label[0] == 0 else \"pos\"\n",
    "    color = (0, 0, 255) if label[0] == 0 else (0, 255, 0)\n",
    "    \n",
    "    vis = cv2.merge([output] * 3)\n",
    "    vis = cv2.resize(vis, (96, 51), interpolation=cv2.INTER_LINEAR)\n",
    "    cv2.putText(vis, text, (2, 12), cv2.FONT_HERSHEY_SIMPLEX, 0.75,\n",
    "        color, 2)\n",
    "\n",
    "    images.append(vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using CV2 functions for visualizing and build_montages from imutils, we can visualize our 49 pairs in 7x7 grid where each grid is a pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage = build_montages(images, (96, 51), (7, 7))[0]\n",
    "plt.imshow(montage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary for specifying some training parameters and model - plot paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "IMG_SHAPE = (28, 28, 1)\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 4\n",
    "\n",
    "BASE_OUTPUT = \"output\"\n",
    "MODEL_PATH = os.path.sep.join([BASE_OUTPUT, \"siamese_model\"])\n",
    "PLOT_PATH = os.path.sep.join([BASE_OUTPUT, \"plot.png\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we import necessary layers we will use for building our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will our network using Keras Functional API. For further information, [Keras Functional API](https://keras.io/guides/functional_api/)\n",
    "\n",
    "Keras Functional treats building Deep Learning models as Directed Acyclic Graphs (DAG) of layers. While building our model, we also specify what the input is for correspoding layer as well. You can study the following code to understand better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_siamese_model(inputShape, embeddingDim=48):\n",
    "    inputs = Input(inputShape)\n",
    "    x = Conv2D(64, (2, 2), padding=\"same\", activation=\"relu\")(inputs)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Conv2D(64, (2, 2), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    pooledOutput = GlobalAveragePooling2D()(x)\n",
    "    outputs = Dense(embeddingDim)(pooledOutput)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have built our model. As we have already stated, we need a similarity measure between the output vectors of our model. Hence, we will define our similarity metric, aka distance function, as in following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vectors):\n",
    "\n",
    "    (featsA, featsB) = vectors\n",
    "\n",
    "    sumSquared = K.sum(K.square(featsA - featsB), axis=1,\n",
    "        keepdims=True)\n",
    "\n",
    "    return K.sqrt(K.maximum(sumSquared, K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, we scale our image pixel values to [0, 1] and handle the tensor shape issue. Then, we obtain our training-ready training and test pair sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = trainX / 255.0\n",
    "testX = testX / 255.0\n",
    "\n",
    "trainX = np.expand_dims(trainX, axis=-1)\n",
    "testX = np.expand_dims(testX, axis=-1)\n",
    "\n",
    "(pairTrain, labelTrain) = make_pairs(trainX, trainY)\n",
    "(pairTest, labelTest) = make_pairs(testX, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is where we built the order of processing of given input images. As in model building, Keras Functional requires us to specify the execution order of functions. Hence, we will build our model as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgA = Input(shape=IMG_SHAPE)\n",
    "imgB = Input(shape=IMG_SHAPE)\n",
    "\n",
    "featureExtractor = build_siamese_model(IMG_SHAPE)\n",
    "featsA = featureExtractor(imgA)\n",
    "featsB = featureExtractor(imgB)\n",
    "distance = Lambda(euclidean_distance)([featsA, featsB])\n",
    "outputs = Dense(1, activation=\"sigmoid\")(distance)\n",
    "model = Model(inputs=[imgA, imgB], outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using keras's summary() function, we can double-check our final model. We can check layer types, output vector shapes, number of trainable parameters, and which layers are connected to which vectors or layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using keras functions, we configure our training design choices and later, we train our model using fit() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "# train the model\n",
    "print(\"training model...\")\n",
    "history = model.fit(\n",
    "    [pairTrain[:, 0], pairTrain[:, 1]], labelTrain[:],\n",
    "    validation_data=([pairTest[:, 0], pairTest[:, 1]], labelTest[:]),\n",
    "    batch_size=BATCH_SIZE, \n",
    "    epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe our training metrics using history variable of our training call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(H):\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    plt.plot(H.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(H.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.plot(H.history[\"accuracy\"], label=\"train_acc\")\n",
    "    plt.plot(H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "    plt.title(\"Training Loss and Accuracy\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend(loc=\"lower left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot the training history\n",
    "plot_training(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, we can test our trained model to understand whether it performs well. Also, we will visualize a couple of test pairs to understand where our model may fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "num_test = len(pairTest)\n",
    "pairs = np.random.choice(num_test, 10)\n",
    "for i, idx in enumerate(pairs):\n",
    "    # load both the images and convert them to grayscale\n",
    "    imageA = pairTest[idx][0]\n",
    "    imageB = pairTest[idx][1]\n",
    "    # create a copy of both the images for visualization purpose\n",
    "    origA = imageA.copy()\n",
    "    origB = imageB.copy()\n",
    "    # add channel a dimension to both the images\n",
    "    imageA = np.expand_dims(imageA, axis=-1)\n",
    "    imageB = np.expand_dims(imageB, axis=-1)\n",
    "    # add a batch dimension to both images\n",
    "    imageA = np.expand_dims(imageA, axis=0)\n",
    "    imageB = np.expand_dims(imageB, axis=0)\n",
    "    # scale the pixel values to the range of [0, 1]\n",
    "    imageA = imageA / 255.0\n",
    "    imageB = imageB / 255.0\n",
    "    # use our siamese model to make predictions on the image pair,\n",
    "    # indicating whether or not the images belong to the same class\n",
    "    preds = model.predict([imageA, imageB])\n",
    "    proba = preds[0][0]\n",
    "    \t# initialize the figure\n",
    "    fig = plt.figure(\"Pair #{}\".format(i + 1), figsize=(4, 2))\n",
    "    plt.suptitle(\"Similarity: {:.2f}\".format(proba))\n",
    "    # show first image\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    plt.imshow(origA, cmap=plt.cm.gray)\n",
    "    plt.axis(\"off\")\n",
    "    # show the second image\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    plt.imshow(origB, cmap=plt.cm.gray)\n",
    "    plt.axis(\"off\")\n",
    "    # show the plot\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
